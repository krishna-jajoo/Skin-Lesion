# -*- coding: utf-8 -*-
"""

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10w62uRAz09qYye6hELDACTHwEromhfSy
"""

import cv2
import numpy as np
import seaborn as sns
import pandas as pd
import os
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torchvision

from google.colab import drive

drive.mount("/content/drive")

data = os.listdir("/content/drive/MyDrive/dermoscopic dataset/dataset/")

image_files = []
mask_files = []
for i in data:
    if ".png" in i:
        mask_files.append(i)
    else:
        image_files.append(i)

from sklearn.model_selection import train_test_split


X_train, X_test, y_train, y_test = train_test_split(
    image_files, mask_files, test_size=0.01
)


def create(pic, directory_path):
    images = []
    masks = []
    p_img = cv2.imread(directory_path + pic)
    name = pic.split(".")[0]
    # print(pic,directory_path+name+'_segmentation.png')
    p_mask = cv2.imread(directory_path + name + "_segmentation.png")
    print(p_mask.shape)

    p_img = cv2.resize(p_img, (120, 120))
    p_mask = cv2.resize(p_mask, (128, 128))
    p_img = cv2.resize(p_img, (128, 128))

    p_mask = cv2.cvtColor(p_mask, cv2.COLOR_BGR2GRAY)

    p_mask[p_mask > 0] = 1

    # print(p_mask.max())
    return p_img, p_mask


import random


def Generator(X_list, batch_size):
    while 1:
        b = 0
        all_i = []
        all_m = []
        random.shuffle(X_list)
        for i in range(batch_size):

            image, mask = create(
                X_list[i - 1], "/content/drive/MyDrive/dermoscopic dataset/dataset/"
            )
            all_i.append(image)
            mask = mask.reshape((128, 128, 1))
            all_m.append(mask)
            b += 1

        all_i = np.array(all_i)
        all_m = np.array(all_m)
        yield np.array(all_i), np.array(all_m)


class Block(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__()
        self.conv1 = nn.Conv2d(in_ch, out_ch, 3)
        self.relu = nn.ReLU()
        self.conv2 = nn.Conv2d(out_ch, out_ch, 3)

    def forward(self, x):
        return self.conv2(self.relu(self.conv1(x)))


class Encoder(nn.Module):
    def __init__(self, chs=(3, 64, 128, 256, 512, 1024)):
        super().__init__()
        self.enc_blocks = nn.ModuleList(
            [Block(chs[i], chs[i + 1]) for i in range(len(chs) - 1)]
        )
        self.pool = nn.MaxPool2d(2)

    def forward(self, x):
        ftrs = []
        for block in self.enc_blocks:
            x = block(x)
            ftrs.append(x)
            x = self.pool(x)
        return ftrs


class Decoder(nn.Module):
    def __init__(self, chs=(1024, 512, 256, 128, 64)):
        super().__init__()
        self.chs = chs
        self.upconvs = nn.ModuleList(
            [nn.ConvTranspose2d(chs[i], chs[i + 1], 2, 2) for i in range(len(chs) - 1)]
        )
        self.dec_blocks = nn.ModuleList(
            [Block(chs[i], chs[i + 1]) for i in range(len(chs) - 1)]
        )

    def forward(self, x, encoder_features):
        for i in range(len(self.chs) - 1):
            x = self.upconvs[i](x)
            enc_ftrs = self.crop(encoder_features[i], x)
            x = torch.cat([x, enc_ftrs], dim=1)
            x = self.dec_blocks[i](x)
        return x

    def crop(self, enc_ftrs, x):
        _, _, H, W = x.shape
        enc_ftrs = torchvision.transforms.CenterCrop([H, W])(enc_ftrs)
        return enc_ftrs


class UNet(nn.Module):
    def __init__(
        self,
        enc_chs=(3, 64, 128, 256, 512, 1024),
        dec_chs=(1024, 512, 256, 128, 64),
        num_class=1,
        retain_dim=False,
        out_sz=(572, 572),
    ):
        super().__init__()
        self.encoder = Encoder(enc_chs)
        self.decoder = Decoder(dec_chs)
        self.head = nn.Conv2d(dec_chs[-1], num_class, 1)
        self.retain_dim = retain_dim

    def forward(self, x):
        enc_ftrs = self.encoder(x)
        out = self.decoder(enc_ftrs[::-1][0], enc_ftrs[::-1][1:])
        out = self.head(out)
        return out


def dice_loss(y_true, y_pred):
    y_true = np.cast(y_true, np.float32)
    y_pred = np.math.sigmoid(y_pred)
    numerator = 2 * np.reduce_sum(y_true * y_pred)
    denominator = np.reduce_sum(y_true + y_pred)

    return 1 - numerator / denominator


model = UNet()

model.compile(loss=dice_loss, optimizer="adam", metrics=["accuracy"])
print(len(X_train))
print(len(X_train) / 5)

gen = Generator(X_train, 5)
model.fit(gen, steps_per_epoch=10, epochs=50)

model.save("/content/drive/MyDrive/dermoscopic dataset/dermo_segmentation_dl_model.h5")

test_data = os.listdir("/content/drive/MyDrive/dermoscopic dataset/dataset2/")

image_files = []
mask_files = []
for i in test_data:
    if ".png" in i:
        mask_files.append(i)
    else:
        image_files.append(i)


def predict_image(p_img):
    p_img = cv2.resize(p_img, (120, 120))
    p_img = cv2.resize(p_img, (128, 128))
    model = torch.load(
        "/content/drive/MyDrive/dermoscopic dataset/dermo_segmentation_dl_model.h5",
        compile=False,
    )

    pred = model.predict(p_img.reshape(1, 128, 128, 3))
    pred[pred > 0.5] = 1
    pred[pred < 0.6] = 0
    pred = pred[:, :, :, 1].reshape((128, 128))

    pred = np.uint8(pred)
    output = pred
    output = cv2.resize(output, (120, 120))
    return output


score = []

source_add = "/content/drive/MyDrive/dermoscopic dataset/dataset2/"

for i in range(len(image_files)):
    image = cv2.imread(source_add + image_files[i])
    b = cv2.imread(source_add + mask_files[i])
    b = cv2.cvtColor(b, cv2.COLOR_BGR2GRAY)
    b = cv2.resize(b, (120, 120))
    output = predict_image(image)
    output = cv2.resize(output, (120, 120))
    intersection = np.logical_and(b, output)
    union = np.logical_or(b, output)
    iou_score = np.sum(intersection) / np.sum(union)
    score.append(iou_score)

score = sum(score) / len(score)

print("IOU score on training dataset is", score)
